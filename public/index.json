[
{
	"uri": "//localhost:1313/1-/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": " Tổng quan Trong quá trình phát triển ứng dụng di động, việc hiểu rõ phản hồi của người dùng là yếu tố sống còn để cải thiện chất lượng sản phẩm, nâng cao trải nghiệm và giữ chân khách hàng. Trên Google Play, mỗi ngày ứng dụng nhận được hàng loạt đánh giá (review) và xếp hạng (rating). Tuy nhiên, dữ liệu này thường tồn tại dưới dạng rời rạc, khó phân tích trực tiếp nếu chỉ nhìn vào bảng thống kê đơn thuần.\nMột báo cáo đánh giá hiệu quả không chỉ dừng lại ở việc tổng hợp số lượng review hay tính trung bình rating, mà cần khai thác sâu hơn:\nNgười dùng đang cảm thấy tích cực hay tiêu cực về ứng dụng?\nChủ đề hoặc vấn đề nào được đề cập nhiều nhất?\nXu hướng cảm xúc thay đổi ra sao theo thời gian?\nĐể trả lời những câu hỏi này, chúng ta cần một giải pháp tự động hóa thu thập, xử lý và trực quan hóa dữ liệu.\nCác Service sử dụng: Quy trình triển khai có thể tận dụng nhiều dịch vụ AWS để đảm bảo tự động, mở rộng linh hoạt và tối ưu chi phí:\n1. AWS Lambda Function:\nChạy function crawler để lấy dữ liệu review từ Google Play. Tự động scale theo số lượng request, không cần quản lý server. 2. Amazon S3:\nLưu trữ dữ liệu thô (raw data) sau khi cào từ Google Play. Dùng làm input/output trong các bước xử lý tiếp theo. 3. Amazon SageMaker (Batch Transform):\nXử lý dữ liệu review bằng mô hình sentiment analysis. Chạy inference theo batch, tiết kiệm chi phí cho workload định kỳ. 4. Amazon EventBridge:\nĐặt lịch trigger pipeline hằng ngày. Đảm bảo quy trình ETL diễn ra tự động mà không cần can thiệp thủ công. 5. Amazon Athena / Amazon Redshift (tùy nhu cầu):\nTruy vấn và tổng hợp dữ liệu đã xử lý. Làm nguồn dữ liệu cho báo cáo/dashboard. 6. Amazon QuickSight:\nTrực quan hóa dữ liệu. Xây dựng dashboard theo dõi xu hướng sentiment, số lượng review, rating trung bình… Ý tưởng: Ý tưởng xuất phát từ nhu cầu thực tế: hằng ngày ứng dụng có hàng trăm đến hàng nghìn review mới trên Google Play. Nếu chỉ nhìn vào bảng rating trung bình thì chưa đủ để phản ánh toàn diện trải nghiệm của người dùng. Do đó, cần một cơ chế:\nTự động cào dữ liệu review: Không cần thao tác thủ công, đảm bảo dữ liệu luôn cập nhật.\nPhân tích cảm xúc bằng AI/ML: Biến các đoạn text của người dùng thành dữ liệu có cấu trúc (sentiment: tích cực, tiêu cực, trung lập).\nTích hợp lưu trữ – xử lý – trực quan hóa: Giúp dữ liệu không chỉ nằm trên file mà còn trở thành thông tin có giá trị kinh doanh.\nHoạt động định kỳ: Trigger theo lịch (ví dụ: mỗi ngày), đảm bảo báo cáo luôn mới nhất.\nMô hình giải quyết bài toán này có thể hình dung như một data pipeline hoàn chỉnh:\nIngestion (Thu thập): Crawl review từ Google Play.\nStorage (Lưu trữ): Đưa dữ liệu raw vào S3.\nProcessing (Xử lý): Làm sạch, phân tích sentiment qua SageMaker.\nAnalytics (Phân tích): Query bằng Athena hoặc Redshift.\nVisualization (Trực quan hóa): Dashboard bằng QuickSight.\nAutomation (Tự động hóa): EventBridge + Step Functions đảm bảo pipeline chạy đều đặn và bền vững.\nNội dung Giới thiệu Chuẩn bị Dựng crawler lấy dữ liệu Tạo Batch Transform job Tạo và đẩy dữ liệu lên Athena Dựng dashboard trên QuickSight Dọn dẹp tài nguyên Bây giờ chúng ta sẽ cùng nhau đi qua các khái niệm cơ bản nhất của việc crawl data\n"
},
{
	"uri": "//localhost:1313/1-/1.1-googleplay/",
	"title": "Google Play",
	"tags": [],
	"description": "",
	"content": "Google Play là gì Khi nói về hệ điều hành Android, không thể không nhắc đến Google Play. Đây không chỉ đơn thuần là một \u0026ldquo;kho ứng dụng\u0026rdquo;, mà là một hệ sinh thái nội dung số toàn diện, đóng vai trò là cổng chính kết nối hàng tỷ người dùng với thế giới ứng dụng, trò chơi và giải trí kỹ thuật số. Được phát triển và duy trì bởi Google, Google Play là nền tảng phân phối chính thức và đáng tin cậy nhất dành cho các thiết bị chạy hệ điều hành Android.\nTừ Android Market đến một Trung tâm Nội dung Toàn diện Tiền thân của Google Play là Android Market, ra mắt vào năm 2008. Ban đầu, đây chỉ là một nơi khiêm tốn để người dùng tải về các ứng dụng cơ bản. Tuy nhiên, nhận thấy tiềm năng to lớn, vào tháng 3 năm 2012, Google đã thực hiện một cuộc tái cấu trúc mang tính bước ngoặt. Họ hợp nhất Android Market, Google Music, và Google eBookstore thành một nền tảng duy nhất dưới cái tên Google Play.\nSự thay đổi này không chỉ là về tên gọi. Nó đánh dấu một sự chuyển mình chiến lược, biến Google Play từ một kho ứng dụng đơn thuần thành một trung tâm giải trí đa phương tiện, nơi người dùng có thể:\nTải ứng dụng và trò chơi: Với hàng triệu lựa chọn, từ các công cụ làm việc, ứng dụng học tập, mạng xã hội cho đến các tựa game bom tấn.\nThưởng thức phim và chương trình TV: Mua hoặc thuê các bộ phim mới nhất.\nĐọc sách và tạp chí: Khám phá một thư viện sách điện tử khổng lồ.\nNghe nhạc và podcast: (Tùy thuộc vào khu vực).\nCác trường dữ liệu thu thập từ Google Play app_details:\nThông tin cơ bản\nTrường Giá trị title Facebook summary Explore the things you love description (mô tả dài, nhiều dòng) descriptionHTML (mô tả có HTML) Cài đặt \u0026amp; Đánh giá\nTrường Giá trị installs 10,000,000,000+ minInstalls 10000000000 realInstalls 10865147603 score 4.3964653 ratings 172790178 reviews 4331694 histogram [17235822, 2481913, 6540240, 14815291, 131716880] Giá \u0026amp; Thanh toán\nTrường Giá trị price 0 free true currency USD sale false saleTime null originalPrice null saleText null offersIAP true inAppProductPrice $0.05 - $10,000.00 per item Nhà phát triển\nTrường Giá trị developer Meta Platforms, Inc. developerId Meta+Platforms,+Inc. developerEmail facebook.android@fb.com developerWebsite https://www.facebook.com/facebook developerAddress null privacyPolicy https://www.facebook.com/about/privacy/ Phân loại\nTrường Giá trị genre Social genreId SOCIAL categories [{\u0026ldquo;name\u0026rdquo;: \u0026ldquo;Social\u0026rdquo;, \u0026ldquo;id\u0026rdquo;: \u0026ldquo;SOCIAL\u0026rdquo;}] Hình ảnh \u0026amp; Media\nTrường Giá trị icon headerImage screenshots Danh sách URL (8 ảnh) video null videoImage null Nội dung \u0026amp; Quảng cáo\nTrường Giá trị contentRating Teen contentRatingDescription null adSupported true containsAds true Thông tin phát hành \u0026amp; cập nhật\nTrường Giá trị released null lastUpdatedOn Sep 10, 2025 updated 1757465488 version Varies with device Thông tin nhận dạng\nTrường Giá trị appId com.facebook.katana url https://play.google.com/store/apps/details?id=com.facebook.katana package_name com.facebook.katana app_review:\nTrường Giá trị package_name com.facebook.katana app_title Facebook url Link reviewId a51a2f0f-6781-42b8-b866-b45341bc0701 userName sanjida yeasmin userImage content trash score ⭐ 1 thumbsUpCount 0 reviewCreatedVersion 529.0.0.44.73 appVersion 529.0.0.44.73 at 2025-09-09 07:38:06 replyContent null repliedAt null crawled_at 2025-09-10 07:38:40 Các sự thật về Google Play Mỗi ngày có khoảng 5000 game được release trên Google Play\nGoogle Play có khoảng 2,066,635 ứng dụng tính đến năm 2025.\nTỉ lệ app vs game: trong số này, khoảng 249,102 là game; phần còn lại là các ứng dụng.\nỨng dụng miễn phí vs trả phí: khoảng 96.98% ứng dụng là miễn phí; chỉ ~3% là trả phí.\nSố ứng dụng được phát hành mới mỗi ngày: ~1,500 ứng dụng mới/ngày được thêm vào Google Play.\n"
},
{
	"uri": "//localhost:1313/",
	"title": "Tăng cường dữ liệu cho báo cáo đánh giá app trên market",
	"tags": [],
	"description": "",
	"content": "Tăng cường dữ liệu cho báo cáo đánh giá app trên Google Play Tổng quan Trong bối cảnh ứng dụng di động ngày càng cạnh tranh, việc theo dõi và phân tích phản hồi của người dùng trên Google Play là yếu tố quan trọng giúp đội ngũ phát triển cải thiện chất lượng sản phẩm. Tuy nhiên, dữ liệu đánh giá thô (reviews) thường rời rạc và khó khai thác ngay cho mục đích báo cáo.\nĐể khắc phục điều này, ta có thể xây dựng một pipeline tự động hóa:\nThu thập dữ liệu đánh giá hằng ngày.\nXử lý và làm giàu dữ liệu (ví dụ phân tích cảm xúc người dùng).\nLưu trữ và trực quan hóa trên dashboard.\nNhờ cách tiếp cận này, báo cáo không chỉ dừng ở số lượng review hay rating, mà còn cung cấp cái nhìn sâu hơn về mức độ hài lòng của người dùng, xu hướng cảm xúc theo thời gian, và các điểm cần cải thiện.\nCác Service sử dụng: Quy trình triển khai có thể tận dụng nhiều dịch vụ AWS để đảm bảo tự động, mở rộng linh hoạt và tối ưu chi phí:\n1. AWS Lambda Function:\nChạy function crawler để lấy dữ liệu review từ Google Play. Tự động scale theo số lượng request, không cần quản lý server. 2. Amazon S3:\nLưu trữ dữ liệu thô (raw data) sau khi cào từ Google Play. Dùng làm input/output trong các bước xử lý tiếp theo. 3. Amazon SageMaker (Batch Transform):\nXử lý dữ liệu review bằng mô hình sentiment analysis. Chạy inference theo batch, tiết kiệm chi phí cho workload định kỳ. 4. Amazon EventBridge:\nĐặt lịch trigger pipeline hằng ngày. Đảm bảo quy trình ETL diễn ra tự động mà không cần can thiệp thủ công. 5. Amazon Athena / Amazon Redshift (tùy nhu cầu):\nTruy vấn và tổng hợp dữ liệu đã xử lý. Làm nguồn dữ liệu cho báo cáo/dashboard. 6. Amazon QuickSight:\nTrực quan hóa dữ liệu. Xây dựng dashboard theo dõi xu hướng sentiment, số lượng review, rating trung bình… → Tuy nhiên để đơn giản và demo một cách thuận tiện nhất có thể bài lab chỉ thực hiện một số những tính năng đơn giản và có thể thực hiện được ngay. Độc giả có thể dễ dàng phát triển thêm các tinh năng khác dựa theo từng nhu cầu và đặc điểm của bản thân.\nNgôn ngữ chính để phục vụ workshop này là python 3.12 Nội dung Giới thiệu Chuẩn bị Dựng crawler lấy dữ liệu Tạo Batch Transform job Tạo và đẩy dữ liệu lên Athena Dựng dashboard trên QuickSight Dọn dẹp tài nguyên "
},
{
	"uri": "//localhost:1313/4-/4.1/",
	"title": "Tạo lambda lấy data app_details",
	"tags": [],
	"description": "",
	"content": "Tạo lambda thu thập dữ liệu app_details Truy cập service Lambda Function Chọn Funtion Chọn Create funtion Đặt tên function là crawl-app-details-maket-chplay Runtime chọn Python3.12 Role: Chọn role đủ quyền :\u0026gt; Add layer cho lambda Kéo xuống cuối chọn: Add a layer Chọn Custum layers Chọn google_play_scrape Thêm code vào lambda: import json import boto3 import datetime from google_play_scraper import app s3 = boto3.client(\u0026#34;s3\u0026#34;) BUCKET = \u0026#34;glutisify-datalake\u0026#34; def save_to_s3(bucket, key, data): s3.put_object( Bucket=bucket, Key=key, Body=data.encode(\u0026#34;utf-8\u0026#34;), ContentType=\u0026#34;application/json\u0026#34; ) print(f\u0026#34;Saved to s3://{bucket}/{key}\u0026#34;) def lambda_handler(event, context): package_list = [ \u0026#34;com.edupia.app.english.kid\u0026#34;, \u0026#34;com.facebook.katana\u0026#34;, \u0026#34;com.zhiliaoapp.musically\u0026#34; ] today = datetime.datetime.utcnow().strftime(\u0026#34;%Y-%m-%d\u0026#34;) crawled_at = datetime.datetime.utcnow().strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) results = [] for package_name in package_list: app_detail = app(package_name, lang=\u0026#34;en\u0026#34;, country=\u0026#34;us\u0026#34;) if \u0026#34;comments\u0026#34; in app_detail: del app_detail[\u0026#34;comments\u0026#34;] app_detail_record = { **app_detail, \u0026#34;package_name\u0026#34;: package_name, \u0026#34;url\u0026#34;: f\u0026#34;https://play.google.com/store/apps/details?id={package_name}\u0026#34;, \u0026#34;crawled_at\u0026#34;: crawled_at } detail_key = f\u0026#34;chplay/app_details/{package_name}/{today}.json\u0026#34; save_to_s3(BUCKET, detail_key, json.dumps(app_detail_record, ensure_ascii=False)) results.append({ \u0026#34;package_name\u0026#34;: package_name, \u0026#34;detail_file\u0026#34;: detail_key }) return { \u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;results\u0026#34;: results } =\u0026gt; Mỗi khi run code nó sẽ lấy dữ liệu app_details thay đổi theo từng ngày\n"
},
{
	"uri": "//localhost:1313/2-/2.1-creates3bucket/",
	"title": "Tạo S3 Bucket",
	"tags": [],
	"description": "",
	"content": "Tạo S3 Bucket Truy cập giao diện AWS Management Console\nTìm S3 Chọn Bucket Chọn Create Bucket Điền tên bucket là glutisify-datalake Tên Bucket phải là duy nhất và không được trùng với tên các bucket đã có.\n3. Chọn Create Bucket\nTên Bucket mọi người có thể tùy ý nha!\nTạo trên CLI Mọi người có thể thực hiện nhanh chóng hơn bằng lệnh cli sau:\naws s3api create-bucket \\ --bucket glutisify-datalake \\ --region ap-southeast-1 \\ --create-bucket-configuration LocationConstraint=ap-southeast-1 "
},
{
	"uri": "//localhost:1313/6/6.1/",
	"title": "Thêm code vào lambda function",
	"tags": [],
	"description": "",
	"content": "Thêm code vào lambda function Truy cập lại giao diện Lambda function vừa tạo ở bước 3.2 Chọn function Chọn function BotTele Tại giao diện code Lambda function Copy đoạn code sau vào ô code: import json import requests import boto3 from datetime import datetime client = boto3.resource(\u0026#39;dynamodb\u0026#39;) def get_current_month_statistics(): try: table = client.Table(\u0026#39;Spend-me\u0026#39;) response = table.scan() total_spend = 0 total_food_spend = 0 total_fuel_spend = 0 current_date = datetime.now() current_month = current_date.month current_year = current_date.year for item in response[\u0026#39;Items\u0026#39;]: if \u0026#39;spend\u0026#39; in item and item[\u0026#39;spend\u0026#39;].isdigit(): spend_amount = int(item[\u0026#39;spend\u0026#39;]) else: continue if \u0026#39;date\u0026#39; in item and \u0026#39;-\u0026#39; in item[\u0026#39;date\u0026#39;]: date = item[\u0026#39;date\u0026#39;] date_parts = date.split(\u0026#39;-\u0026#39;) if len(date_parts) == 3: item_month = int(date_parts[1]) item_year = int(date_parts[2]) if item_month != current_month or item_year != current_year: continue total_spend += spend_amount if \u0026#39;spend_name\u0026#39; in item: spend_name = item[\u0026#39;spend_name\u0026#39;].lower() if \u0026#39;ăn\u0026#39; in spend_name: total_food_spend += spend_amount elif \u0026#39;đổ xăng\u0026#39; in spend_name: total_fuel_spend += spend_amount return total_spend, total_food_spend, total_fuel_spend except Exception as e: print(f\u0026#34;Error in get_current_month_statistics: {e}\u0026#34;) raise def lambda_handler(event, context): try: body = json.loads(event[\u0026#39;body\u0026#39;]) chat_id = body[\u0026#39;message\u0026#39;][\u0026#39;chat\u0026#39;][\u0026#39;id\u0026#39;] message_text = body[\u0026#39;message\u0026#39;][\u0026#39;text\u0026#39;] url = \u0026#34;https://api.telegram.org/bot\u0026lt;bot-token\u0026gt;/sendMessage\u0026#34; if message_text.startswith(\u0026#39;/sum\u0026#39;): total_spend, total_food_spend, total_fuel_spend = get_current_month_statistics() response_text = (f\u0026#34;Đây là thống kê chi tiết chi tiêu tháng này của bạn:\\n\u0026#34; f\u0026#34;Tổng chi tiêu: {total_spend}\\n\u0026#34; f\u0026#34;Tổng tiền ăn: {total_food_spend}\\n\u0026#34; f\u0026#34;Tổng tiền đổ xăng: {total_fuel_spend}\u0026#34;) elif message_text.startswith(\u0026#39;/chi\u0026#39;): parts = message_text.split(\u0026#39;|\u0026#39;) if len(parts) == 3: spend = int(parts[0].strip().split()[1]) # Extract the amount from the command spend_name = parts[1].strip() # Extract the spend name date = parts[2].strip() # Extract the date formatted_date = datetime.strptime(date, \u0026#39;%d-%m-%Y\u0026#39;).strftime(\u0026#39;%Y-%m-%d\u0026#39;) # Format the date properly table = client.Table(\u0026#39;\u0026lt;table-name\u0026gt;\u0026#39;) response = table.put_item( Item={ \u0026#39;id\u0026#39;: str(datetime.now().timestamp()), \u0026#39;spend\u0026#39;: str(spend), \u0026#39;spend_name\u0026#39;: spend_name, \u0026#39;date\u0026#39;: formatted_date } ) response_text = \u0026#34;Dữ liệu đã ghi vào cơ sở dữ liệu thành công.\u0026#34; else: response_text = \u0026#34;Sai định dạng. Định dạng đúng: /chi 10000 | Mua áo | 12-7-2023\u0026#34; elif message_text.startswith(\u0026#39;/show\u0026#39;): table = client.Table(\u0026#39;Spend-me\u0026#39;) response = table.scan(Limit=5) items = response[\u0026#39;Items\u0026#39;] response_text = \u0026#34;Top 5 ghi chép mới nhất:\\n\u0026#34; for item in items: response_text += f\u0026#34;- ID: {item.get(\u0026#39;id\u0026#39;, \u0026#39;N/A\u0026#39;)}, Spend: {item.get(\u0026#39;spend\u0026#39;, \u0026#39;0\u0026#39;)}, Name: {item.get(\u0026#39;spend_name\u0026#39;, \u0026#39;N/A\u0026#39;)}, Date: {item.get(\u0026#39;date\u0026#39;, \u0026#39;N/A\u0026#39;)}\\n\u0026#34; else: response_text = \u0026#34;Lệnh không hợp lệ. Vui lòng sử dụng /chi để nhập chi tiêu hoặc /sum để xem thống kê.\u0026#34; payload = {\u0026#39;chat_id\u0026#39;: chat_id, \u0026#39;text\u0026#39;: response_text} requests.post(url, json=payload) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;message\u0026#34;: \u0026#34;Success\u0026#34;})} except Exception as e: print(f\u0026#34;Error in lambda_handler: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;message\u0026#34;: \u0026#34;Error\u0026#34;})} Những cái cần sửa:\n\u0026lt;bot-token\u0026gt;: token lấy của chatbot tại bước 2\n\u0026lt;table-name\u0026gt;: tên bảng Dynamodb đã tạo\nCác bạn có thể để id tự tăng hoặc để theo ngày tháng giống mình :))\nNhấn Deploy để lưu code: Code được lưu thành công "
},
{
	"uri": "//localhost:1313/2-/2.2-createlayer/",
	"title": "Add Layer google_play_scraper",
	"tags": [],
	"description": "",
	"content": "Add Layer google_play_scraper Có rất nhiều layer có sẵn được các người dùng khác đóng gói và chia sẻ trên các repo github. Tuy nhiên đó chỉ là các layer rất là phổ biến còn đa số các thư viện còn lại sẽ không được như vậy.\nTại đây mình sẽ hướng dẫn bạn đóng gói chung cho các layer\nMột vài cái cần phải lưu ý:\nKhông phải package nào cũng đóng gói được thành layer, AWS chỉ cho phép kích thước zip tối đa là 50MB, và 250MB trên s3 Việc tạo package bạn có thể tạo ở local và đấy ngược lên s3 Việc hiện tại cần làm:\nChuẩn bị một server linux (có thể là máy bạn) hoặc dùng trực tiếp cloud shell Đã cài aws cli Thực hiện lần lượt các câu lệnh sau: Tạo cấu trúc thư mục mkdir google_play_scraper_layer cd google_play_scraper_layer mkdir -p python Cài thư viện Python pip install google_play_scraper -t python/ Đóng gói zip zip -r9 google_play_scraper_layer.zip python Upload file lên s3 aws s3 cp dist/google_play_scraper-0.1.0-py3-none-any.whl s3://glutisify/package/ Tạo layer trên giao diện Trong giao diện AWS Management Console\nChọn Lambda Chọn Layer Chọn Create layer Tiếp tục chọn Tại name điền google_play_scraper Tại description điền google_play_scraper package Chọn upload từ s3 Tại Amazon S3 link URL điền s3://glutisify-datalake/package/google_play_scraper_layer.zip Tại architectures chọn arm64, x86_64 Chọn Python 3.12 Chọn Create Tham khảo pip install google_play_scraper\n"
},
{
	"uri": "//localhost:1313/2-/",
	"title": "Các bước chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Các bước chuẩn bị Trong bài thực hành này, chúng ta sẽ xây dựng một mô hình theo sơ đồ bên dưới:\nNội dung Tạo S3 Bucket Tạo Lambda Function Add Layer "
},
{
	"uri": "//localhost:1313/1-/1.2-crawldata/",
	"title": "Crawl data",
	"tags": [],
	"description": "",
	"content": "Crawl data Crawl data là quá trình tự động thu thập thông tin từ các trang web trên Internet. Để hiểu cách nó hoạt động, hãy tưởng tượng rằng bạn có một bot trên mạng Internet, nhiệm vụ của nó là cứ nhìn thấy cái gì có ích thì mang về.\nBot bắt đầu bằng việc điều hướng qua các trang web, như một người du lịch dạo chơi qua các con đường trên bản đồ. Khi bot đến một trang web, nó quét qua nội dung của trang đó, giống như việc bạn đọc qua các trang sách để tìm kiếm thông tin. bot phân tích các phần tử của trang web như các liên kết, văn bản, hình ảnh, video, và dữ liệu cấu trúc.\nSau đó, bot thu thập dữ liệu từ các phần của trang web chứa thông tin bạn quan tâm, như việc bạn ghi chú lại những điều quan trọng khi đọc sách. Dữ liệu này có thể là văn bản, hình ảnh, video, hoặc dữ liệu có cấu trúc như bảng biểu.\nQuá trình này được lặp lại cho đến khi bot đã thu thập đủ thông tin hoặc đã truy cập qua tất cả các trang web trong danh sách. Đối với những trang web thường xuyên cập nhật thông tin, bạn có thể lập lịch cho bot để thực hiện lại quá trình crawl định kỳ để đảm bảo dữ liệu của bạn luôn cập nhật.\nTuy nhiên, việc crawl data cần phải được thực hiện cẩn thận và tuân thủ các quy định về bản quyền và chính sách riêng tư của các trang web. Vi phạm các quy định này có thể dẫn đến hậu quả pháp lý.\nCứ cái gì nhìn thấy trên web thì đều có thể lấy về bằng code được .\nCác phương pháp để crawl data Dùng Ai Với sự nổi lên của các mô hình ngôn ngữ lớn thì việc crawl bằng Ai có lẽ cũng chẳng xa lạ gì?\nNổi bật với:\nFirecrawl Apify Rapid Data Miner =\u0026gt; Thuận tiện nhanh gọn tuy nhiên sẽ phải trả phí để sử dụng\nTruyền thống Puppeteer Selenium Scrapy Bs4 Playwright =\u0026gt; Khó dùng, phải code và dựng hạ tầng để sử dụng\n"
},
{
	"uri": "//localhost:1313/4-/4.2/",
	"title": "Tạo lambda lấy data app_reviews",
	"tags": [],
	"description": "",
	"content": "Tạo lambda thu thập dữ liệu app_review Truy cập service Lambda Function Chọn Funtion Chọn Create funtion Đặt tên function là crawl-review-maker-chplay Runtime chọn Python3.12 Role: Chọn role đủ quyền :\u0026gt; Add layer cho lambda Kéo xuống cuối chọn: Add a layer Chọn Custum layers Chọn google_play_scrape Thêm code vào lambda: import json import boto3 import datetime from google_play_scraper import app, reviews, Sort s3 = boto3.client(\u0026#34;s3\u0026#34;) BUCKET = \u0026#34;glutisify-datalake\u0026#34; def save_to_s3(bucket, key, data): s3.put_object( Bucket=bucket, Key=key, Body=data.encode(\u0026#34;utf-8\u0026#34;), ContentType=\u0026#34;application/json\u0026#34; ) print(f\u0026#34;Saved to s3://{bucket}/{key}\u0026#34;) def lambda_handler(event, context): package_list = [ \u0026#34;com.edupia.app.english.kid\u0026#34;, \u0026#34;com.facebook.katana\u0026#34;, \u0026#34;com.zhiliaoapp.musically\u0026#34; ] today = datetime.datetime.utcnow().strftime(\u0026#34;%Y-%m-%d\u0026#34;) crawled_at = datetime.datetime.utcnow().strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) days = 90 start_date = datetime.datetime.utcnow() - datetime.timedelta(days=days) results = [] for package_name in package_list: app_detail = app(package_name, lang=\u0026#34;en\u0026#34;, country=\u0026#34;us\u0026#34;) if \u0026#34;comments\u0026#34; in app_detail: del app_detail[\u0026#34;comments\u0026#34;] app_detail_record = { **app_detail, \u0026#34;package_name\u0026#34;: package_name, \u0026#34;url\u0026#34;: f\u0026#34;https://play.google.com/store/apps/details?id={package_name}\u0026#34;, \u0026#34;crawled_at\u0026#34;: crawled_at } detail_key = f\u0026#34;chplay/app_details/{package_name}/{today}.json\u0026#34; save_to_s3(BUCKET, detail_key, json.dumps(app_detail_record, ensure_ascii=False)) # ---- Crawl Reviews (crawl nhiều để đảm bảo có đủ review 7 ngày gần nhất) ---- app_reviews, _ = reviews( package_name, lang=\u0026#34;en\u0026#34;, country=\u0026#34;us\u0026#34;, # count=1000, # crawl nhiều, rồi filter sau sort=Sort.NEWEST ) review_lines = [] for r in app_reviews: review_date = r.get(\u0026#34;at\u0026#34;) if review_date and review_date \u0026gt;= start_date: review_obj = { \u0026#34;package_name\u0026#34;: package_name, \u0026#34;app_title\u0026#34;: app_detail.get(\u0026#34;title\u0026#34;), \u0026#34;url\u0026#34;: f\u0026#34;https://play.google.com/store/apps/details?id={package_name}\u0026#34;, \u0026#34;reviewId\u0026#34;: r.get(\u0026#34;reviewId\u0026#34;), \u0026#34;userName\u0026#34;: r.get(\u0026#34;userName\u0026#34;), \u0026#34;userImage\u0026#34;: r.get(\u0026#34;userImage\u0026#34;), \u0026#34;content\u0026#34;: r.get(\u0026#34;content\u0026#34;), \u0026#34;score\u0026#34;: r.get(\u0026#34;score\u0026#34;), \u0026#34;thumbsUpCount\u0026#34;: r.get(\u0026#34;thumbsUpCount\u0026#34;), \u0026#34;reviewCreatedVersion\u0026#34;: r.get(\u0026#34;reviewCreatedVersion\u0026#34;), \u0026#34;at\u0026#34;: review_date.strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;), \u0026#34;replyContent\u0026#34;: r.get(\u0026#34;replyContent\u0026#34;), \u0026#34;repliedAt\u0026#34;: r.get(\u0026#34;repliedAt\u0026#34;).strftime(\u0026#34;%Y-%m-%d %H:%M:%S\u0026#34;) if r.get(\u0026#34;repliedAt\u0026#34;) else None, \u0026#34;appVersion\u0026#34;: r.get(\u0026#34;appVersion\u0026#34;), \u0026#34;crawled_at\u0026#34;: crawled_at } review_lines.append(json.dumps(review_obj, ensure_ascii=False)) reviews_key = f\u0026#34;chplay/app_reviews/{package_name}/{today}.jsonl\u0026#34; save_to_s3(BUCKET, reviews_key, \u0026#34;\\n\u0026#34;.join(review_lines)) results.append({ \u0026#34;package_name\u0026#34;: package_name, \u0026#34;detail_file\u0026#34;: detail_key, \u0026#34;reviews_file\u0026#34;: reviews_key, \u0026#34;total_reviews\u0026#34;: len(review_lines) }) return { \u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;results\u0026#34;: results } =\u0026gt; Mỗi khi run code nó sẽ lấy dữ liệu app_details thay đổi theo từng tuần, lấy theo tuần do thông thường app sẽ ít review nếu đã release lâu ngày.\n"
},
{
	"uri": "//localhost:1313/1-/1.3-layer/",
	"title": "Layer",
	"tags": [],
	"description": "",
	"content": "Về Layer Layer ở đây là các package, bên ngoài các method gốc của ngôn ngữ lập trình thông thường. Để đơn giản hãy tưởng tượng layer tương tự như các thư viện trong python và mình chỉ việc import vào và sử dụng nó như bình thường(mặc định lambda function không có sẵn các thư viện mà phải thêm vào thông qua layers).\nMỗi Lambda function được add tối đa 5 layers.\nMột lambda function không thể thêm nhiều layer quá số bit cho trước nếu thêm quá sẽ hiện cảnh báo đỏ.\nCó 2 cách để thêm layer:\nThêm trực tiếp bằng cách zip các file trong thư viện gốc rồi đẩy lên layer (tốn thời gian để nén và có khi ko ăn với lambda hoặc cũng có thể zip thiếu). Cũng zip lại và tải trực tiếp vào lambda function. The layer bằng cách copy ARNs(của những người đã tạo trước đó) cùng với version tương ứng. Link ARNs tham khảo: https://github.com/keithrozario/Klayers\n"
},
{
	"uri": "//localhost:1313/4-/4.3/",
	"title": "Tạo lambda lấy triger module xử lý dữ liệu",
	"tags": [],
	"description": "",
	"content": "Tạo lambda thu thập dữ liệu app_review Truy cập service Lambda Function Chọn Funtion Chọn Create funtion Đặt tên function là run-sentiment-app-review-batch-transform Runtime chọn Python3.12 Role: Chọn role đủ quyền :\u0026gt; Thêm code vào lambda: import json import boto3 import urllib.parse import time MODEL_NAME = \u0026#34;distilbert-sst2-fixed-v5\u0026#34; INPUT_BUCKET = \u0026#34;glutisify-datalake\u0026#34; OUTPUT_BUCKET = \u0026#34;glutisify-datalake\u0026#34; INPUT_PREFIX = \u0026#34;chplay/app_reviews/com.facebook.katana/\u0026#34; OUTPUT_PREFIX = \u0026#34;chplay-gold/app_reviews/com.facebook.katana/\u0026#34; sagemaker = boto3.client(\u0026#34;sagemaker\u0026#34;) s3 = boto3.client(\u0026#34;s3\u0026#34;) def create_batch_job(input_uri, filename): \u0026#34;\u0026#34;\u0026#34;Tạo batch transform job với cấu hình chuẩn cho JSON Lines.\u0026#34;\u0026#34;\u0026#34; file_date = filename.replace(\u0026#34;.json\u0026#34;, \u0026#34;\u0026#34;) job_name = f\u0026#34;{MODEL_NAME}-batch-{file_date}-{int(time.time())}\u0026#34; response = sagemaker.create_transform_job( TransformJobName=job_name, ModelName=MODEL_NAME, MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=\u0026#34;SingleRecord\u0026#34;, TransformInput={ \u0026#34;DataSource\u0026#34;: {\u0026#34;S3DataSource\u0026#34;: {\u0026#34;S3DataType\u0026#34;: \u0026#34;S3Prefix\u0026#34;, \u0026#34;S3Uri\u0026#34;: input_uri}}, \u0026#34;ContentType\u0026#34;: \u0026#34;application/jsonlines\u0026#34;, \u0026#34;SplitType\u0026#34;: \u0026#34;Line\u0026#34; }, TransformOutput={ \u0026#34;S3OutputPath\u0026#34;: f\u0026#34;s3://{OUTPUT_BUCKET}/{OUTPUT_PREFIX}\u0026#34;, \u0026#34;Accept\u0026#34;: \u0026#34;application/jsonlines\u0026#34;, \u0026#34;AssembleWith\u0026#34;: \u0026#34;Line\u0026#34; }, TransformResources={\u0026#34;InstanceType\u0026#34;: \u0026#34;ml.m5.large\u0026#34;, \u0026#34;InstanceCount\u0026#34;: 1}, ) return { \u0026#34;jobName\u0026#34;: job_name, \u0026#34;jobArn\u0026#34;: response[\u0026#34;TransformJobArn\u0026#34;], } def process_file(bucket, key): \u0026#34;\u0026#34;\u0026#34;Kiểm tra và xử lý một file từ S3.\u0026#34;\u0026#34;\u0026#34; filename = key.split(\u0026#34;/\u0026#34;)[-1] if not filename.endswith(\u0026#34;.json\u0026#34;): return None input_uri = f\u0026#34;s3://{bucket}/{key}\u0026#34; output_key = f\u0026#34;{OUTPUT_PREFIX}{filename}.out\u0026#34; try: s3.head_object(Bucket=OUTPUT_BUCKET, Key=output_key) return None except s3.exceptions.ClientError as e: if e.response[\u0026#39;Error\u0026#39;][\u0026#39;Code\u0026#39;] == \u0026#39;404\u0026#39;: return create_batch_job(input_uri, filename) else: print(f\u0026#34;Lỗi khi kiểm tra S3: {e}\u0026#34;) raise def lambda_handler(event, context): \u0026#34;\u0026#34;\u0026#34;Entry point: Xử lý trigger từ S3 hoặc chạy thủ công.\u0026#34;\u0026#34;\u0026#34; try: jobs = [] if \u0026#34;Records\u0026#34; in event: print(\u0026#34;Chế độ trigger từ S3 Event.\u0026#34;) for record in event[\u0026#34;Records\u0026#34;]: bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = urllib.parse.unquote_plus(record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;]) if bucket == INPUT_BUCKET and key.startswith(INPUT_PREFIX): job = process_file(bucket, key) if job: jobs.append(job) else: print(\u0026#34;Chế độ chạy thủ công (manual).\u0026#34;) response = s3.list_objects_v2(Bucket=INPUT_BUCKET, Prefix=INPUT_PREFIX) for obj in response.get(\u0026#34;Contents\u0026#34;, []): job = process_file(INPUT_BUCKET, obj[\u0026#34;Key\u0026#34;]) if job: jobs.append(job) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: json.dumps( {\u0026#34;message\u0026#34;: f\u0026#34;{len(jobs)} job(s) created\u0026#34;, \u0026#34;jobs\u0026#34;: jobs}, ensure_ascii=False ), } except Exception as e: return {\u0026#34;statusCode\u0026#34;: 500, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: str(e)})} =\u0026gt; Mỗi khi run code nó sẽ gọi job batch transform trên sagemaker ai để sử lý dữ liệu review đã crawl về\n"
},
{
	"uri": "//localhost:1313/2-/2.3-createmodel/",
	"title": "Tạo model distilbert-sst2 và đẩy lên s3",
	"tags": [],
	"description": "",
	"content": "Tải model về máy Tạo file main.py: vi main.py Thêm nội dung file:\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer model_id = \u0026#34;distilbert-base-uncased-finetuned-sst-2-english\u0026#34; tokenizer = AutoTokenizer.from_pretrained(model_id) model = AutoModelForSequenceClassification.from_pretrained(model_id) tokenizer.save_pretrained(\u0026#34;./distilbert-sst2\u0026#34;) model.save_pretrained(\u0026#34;./distilbert-sst2\u0026#34;) Run code:\nuv run main.py Truy cập vào phần model Tạo 1 folder mới chưa inference mkdir code cd code vi inference.py Thêm nội dung:\nimport json import os from transformers import pipeline from langdetect import detect, LangDetectException def model_fn(model_dir): \u0026#34;\u0026#34;\u0026#34; Hàm này được SageMaker gọi để tải model. Linh hoạt với cấu trúc thư mục của model. \u0026#34;\u0026#34;\u0026#34; candidate_subdir = os.path.join(model_dir, \u0026#34;model\u0026#34;) model_path = candidate_subdir if os.path.isdir(candidate_subdir) else model_dir sentiment_pipeline = pipeline( \u0026#34;text-classification\u0026#34;, model=model_path, tokenizer=model_path, device=-1, top_k=1 ) return sentiment_pipeline def input_fn(request_body, request_content_type): \u0026#34;\u0026#34;\u0026#34; Hàm này xử lý một dòng JSON duy nhất, phù hợp với BatchStrategy=SINGLE_RECORD. \u0026#34;\u0026#34;\u0026#34; if request_content_type == \u0026#39;application/jsonlines\u0026#39;: if isinstance(request_body, bytes): request_body = request_body.decode(\u0026#39;utf-8\u0026#39;) return json.loads(request_body) else: raise ValueError(f\u0026#34;Unsupported content type: {request_content_type}\u0026#34;) def predict_fn(input_data, model): \u0026#34;\u0026#34;\u0026#34; Hàm này thực hiện dự đoán trên một record duy nhất. Quan trọng: Nó sẽ phát hiện ngôn ngữ trước khi dự đoán. \u0026#34;\u0026#34;\u0026#34; review_text = input_data.get(\u0026#39;content\u0026#39;, \u0026#39;\u0026#39;).strip() if not review_text: input_data[\u0026#39;sentiment_prediction\u0026#39;] = {\u0026#39;label\u0026#39;: \u0026#39;NO_CONTENT\u0026#39;} return input_data try: lang = detect(review_text) if lang == \u0026#39;en\u0026#39;: sentiment_result = model(review_text)[0] input_data[\u0026#39;sentiment_prediction\u0026#39;] = sentiment_result else: input_data[\u0026#39;sentiment_prediction\u0026#39;] = {\u0026#39;label\u0026#39;: \u0026#39;NON_ENGLISH\u0026#39;, \u0026#39;language_detected\u0026#39;: lang} except LangDetectException: input_data[\u0026#39;sentiment_prediction\u0026#39;] = {\u0026#39;label\u0026#39;: \u0026#39;LANG_DETECT_ERROR\u0026#39;} return input_data def output_fn(prediction, accept): \u0026#34;\u0026#34;\u0026#34; Hàm này định dạng kết quả đầu ra cho một record. \u0026#34;\u0026#34;\u0026#34; if accept == \u0026#34;application/jsonlines\u0026#34;: return json.dumps(prediction, ensure_ascii=False) + \u0026#39;\\n\u0026#39; raise ValueError(f\u0026#34;Unsupported accept type: {accept}\u0026#34;) Nén lại tành file model..tar tar -czf model.tar.gz distilbert-sst2/ Đẩy lên s3 aws s3 cp distilbert-sst2-fixed.tar.gz s3://glutisify-datalake/models/distilbert-sst2-fixed/ Các file code trên chỉ hiệu quả khi bạn cài xong môi trường, ở đây mình dùng uv do uv nhanh gấp 10 lần pip\n"
},
{
	"uri": "//localhost:1313/3-/",
	"title": "Tạo model trên Sagemaker",
	"tags": [],
	"description": "",
	"content": "Tạo model trên sagemaker AI Truy cập Sagemaker AI Chọn Inference Chọn Models Chọn Create Model Điền các cấu hình cho model Model name distilbert-sst2 IAM role: abcxyz (tạo 1 IAM role có đủ quyền) Tiếp tục kéo xuống và điền Location of inference code image 763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/huggingface-pytorch-inference:1.13.1-transformers4.26.0-cpu-py39-ubuntu20.04 Location of model artifacts s3://glutisify-datalake/models/distilbert-sst2/model.tar.gz Các biến môi trường trong model: Key Value HF_TASK text-classification SAGEMAKER_PROGRAM inference.py SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/model/code SAGEMAKER_CONTAINER_LOG_LEVEL 20 SAGEMAKER_REGION ap-southeast-1 Kéo xuống cuối Để các config còn lại mặc định Chọn Create "
},
{
	"uri": "//localhost:1313/2-/2.4-createigw/",
	"title": "Tạo 1 IAM role đủ quyền",
	"tags": [],
	"description": "",
	"content": "Tạo 1 IAM role đủ quyền Trong giao diện IAM\nKéo xuống cuối chọn Role Chọn Create role Đặt tên là: 1-role-d4jxk5zk Lần lượt thêm cái role:\nCloud Watch full access { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::glutisify-datalake/*\u0026#34; } ] } Sagemaker create Batch Transform job { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;sagemaker:CreateTransformJob\u0026#34;, \u0026#34;sagemaker:DescribeTransformJob\u0026#34;, \u0026#34;sagemaker:StopTransformJob\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sagemaker:ap-southeast-1:975050197456:transform-job/*\u0026#34; } ] } Sagemaker full access {\r\u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;,\r\u0026#34;Statement\u0026#34;: [\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;AmazonDataZoneStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;datazone:*\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;ReadOnlyStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;kms:DescribeKey\u0026#34;,\r\u0026#34;kms:ListAliases\u0026#34;,\r\u0026#34;iam:ListRoles\u0026#34;,\r\u0026#34;iam:ListPolicies\u0026#34;,\r\u0026#34;sso:DescribeRegisteredRegions\u0026#34;,\r\u0026#34;s3:ListAllMyBuckets\u0026#34;,\r\u0026#34;redshift:DescribeClusters\u0026#34;,\r\u0026#34;redshift-serverless:ListWorkgroups\u0026#34;,\r\u0026#34;ec2:DescribeSecurityGroups\u0026#34;,\r\u0026#34;ec2:DescribeSubnets\u0026#34;,\r\u0026#34;ec2:DescribeVpcs\u0026#34;,\r\u0026#34;secretsmanager:ListSecrets\u0026#34;,\r\u0026#34;iam:ListUsers\u0026#34;,\r\u0026#34;glue:GetDatabases\u0026#34;,\r\u0026#34;codeconnections:ListConnections\u0026#34;,\r\u0026#34;codeconnections:ListTagsForResource\u0026#34;,\r\u0026#34;codewhisperer:ListProfiles\u0026#34;,\r\u0026#34;bedrock:ListInferenceProfiles\u0026#34;,\r\u0026#34;bedrock:ListFoundationModels\u0026#34;,\r\u0026#34;bedrock:ListTagsForResource\u0026#34;,\r\u0026#34;aoss:ListSecurityPolicies\u0026#34;,\r\u0026#34;quicksight:DescribeAccountSubscription\u0026#34;,\r\u0026#34;cloudformation:ValidateTemplate\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;BucketReadOnlyStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;s3:ListBucket\u0026#34;,\r\u0026#34;s3:GetBucketLocation\u0026#34;,\r\u0026#34;s3:ListBucketVersions\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::*\u0026#34;\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;ReadManagedBlueprintTemplatesStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::default-env-blueprint-*/*\u0026#34;,\r\u0026#34;arn:aws:s3:*:*:accesspoint/env-blueprint-accesspoint*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;ArnLike\u0026#34;: {\r\u0026#34;s3:DataAccessPointArn\u0026#34;: \u0026#34;arn:aws:s3:*:*:accesspoint/env-blueprint-accesspoint\u0026#34;\r},\r\u0026#34;StringNotEquals\u0026#34;: {\r\u0026#34;aws:ResourceAccount\u0026#34;: \u0026#34;${aws:PrincipalAccount}\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;CreateBucketStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;s3:CreateBucket\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::amazon-datazone*\u0026#34;,\r\u0026#34;arn:aws:s3:::amazon-sagemaker*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;ConfigureBucketStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;s3:PutBucketCORS\u0026#34;,\r\u0026#34;s3:PutBucketPolicy\u0026#34;,\r\u0026#34;s3:PutBucketVersioning\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::amazon-sagemaker*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;aws:ResourceAccount\u0026#34;: \u0026#34;${aws:PrincipalAccount}\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;PutObjectStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;s3:PutObject\u0026#34;,\r\u0026#34;s3:GetObject\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:s3:::amazon-sagemaker*/*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;aws:ResourceAccount\u0026#34;: \u0026#34;${aws:PrincipalAccount}\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;RamCreateResourceStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;ram:CreateResourceShare\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEqualsIfExists\u0026#34;: {\r\u0026#34;ram:RequestedResourceType\u0026#34;: \u0026#34;datazone:Domain\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;RamResourceStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;ram:DeleteResourceShare\u0026#34;,\r\u0026#34;ram:AssociateResourceShare\u0026#34;,\r\u0026#34;ram:DisassociateResourceShare\u0026#34;,\r\u0026#34;ram:RejectResourceShareInvitation\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringLike\u0026#34;: {\r\u0026#34;ram:ResourceShareName\u0026#34;: [\r\u0026#34;DataZone*\u0026#34;\r]\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;RamResourceReadOnlyStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;ram:GetResourceShares\u0026#34;,\r\u0026#34;ram:GetResourceShareInvitations\u0026#34;,\r\u0026#34;ram:GetResourceShareAssociations\u0026#34;,\r\u0026#34;ram:ListResourceSharePermissions\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;RamAssociateResourceSharePermissionStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;ram:AssociateResourceSharePermission\u0026#34;,\r\u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;,\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;ram:PermissionArn\u0026#34;: [\r\u0026#34;arn:aws:ram::aws:permission/AWSRAMDefaultPermissionAmazonDataZoneDomain\u0026#34;,\r\u0026#34;arn:aws:ram::aws:permission/AWSRAMPermissionAmazonDataZoneDomainFullAccessWithPortalAccess\u0026#34;,\r\u0026#34;arn:aws:ram::aws:permission/AWSRAMPermissionsAmazonDatazoneDomainExtendedServiceAccess\u0026#34;,\r\u0026#34;arn:aws:ram::aws:permission/AWSRAMPermissionsAmazonDatazoneDomainExtendedServiceWithPortalAccess\u0026#34;\r]\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;IAMPassRoleStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;iam:PassRole\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:iam::*:role/AmazonDataZone*\u0026#34;,\r\u0026#34;arn:aws:iam::*:role/service-role/AmazonDataZone*\u0026#34;,\r\u0026#34;arn:aws:iam::*:role/service-role/AmazonSageMaker*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;iam:passedToService\u0026#34;: \u0026#34;datazone.amazonaws.com\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;IAMGetPolicyStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: \u0026#34;iam:GetPolicy\u0026#34;,\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:iam::*:policy/service-role/AmazonDataZoneRedshiftAccessPolicy*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;DataZoneTagOnCreateDomainProjectTags\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;secretsmanager:TagResource\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:*:*:secret:AmazonDataZone-*\u0026#34;,\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;ForAllValues:StringEquals\u0026#34;: {\r\u0026#34;aws:TagKeys\u0026#34;: [\r\u0026#34;AmazonDataZoneDomain\u0026#34;,\r\u0026#34;AmazonDataZoneProject\u0026#34;\r]\r},\r\u0026#34;StringLike\u0026#34;: {\r\u0026#34;aws:RequestTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;dzd*\u0026#34;,\r\u0026#34;aws:ResourceTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;dzd*\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;DataZoneTagOnCreate\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;secretsmanager:TagResource\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:*:*:secret:AmazonDataZone-*\u0026#34;,\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;ForAllValues:StringEquals\u0026#34;: {\r\u0026#34;aws:TagKeys\u0026#34;: [\r\u0026#34;AmazonDataZoneDomain\u0026#34;\r]\r},\r\u0026#34;StringLike\u0026#34;: {\r\u0026#34;aws:RequestTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;dzd*\u0026#34;,\r\u0026#34;aws:ResourceTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;dzd*\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;CreateSecretStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;secretsmanager:CreateSecret\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:secretsmanager:*:*:secret:AmazonDataZone-*\u0026#34;,\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringLike\u0026#34;: {\r\u0026#34;aws:RequestTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;dzd*\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;ConnectionStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;codeconnections:GetConnection\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:codeconnections:*:*:connection/*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;TagCodeConnectionsStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;codeconnections:TagResource\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:codeconnections:*:*:connection/*\u0026#34;,\r\u0026#34;arn:aws:codeconnections:*:*:host/*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;ForAllValues:StringEquals\u0026#34;: {\r\u0026#34;aws:TagKeys\u0026#34;: [\r\u0026#34;for-use-with-all-datazone-projects\u0026#34;\r]\r},\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;aws:RequestTag/for-use-with-all-datazone-projects\u0026#34;: \u0026#34;true\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;UntagCodeConnectionsStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;codeconnections:UntagResource\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:codeconnections:*:*:connection/*\u0026#34;,\r\u0026#34;arn:aws:codeconnections:*:*:host/*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;ForAllValues:StringEquals\u0026#34;: {\r\u0026#34;aws:TagKeys\u0026#34;: \u0026#34;for-use-with-all-datazone-projects\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;SSMParameterStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;ssm:GetParameter\u0026#34;,\r\u0026#34;ssm:GetParametersByPath\u0026#34;,\r\u0026#34;ssm:PutParameter\u0026#34;,\r\u0026#34;ssm:DeleteParameter\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:ssm:*:*:parameter/amazon/datazone/q*\u0026#34;,\r\u0026#34;arn:aws:ssm:*:*:parameter/amazon/datazone/genAI*\u0026#34;,\r\u0026#34;arn:aws:ssm:*:*:parameter/amazon/datazone/profiles*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;UseKMSKeyPermissionsStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;kms:Decrypt\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringEquals\u0026#34;: {\r\u0026#34;aws:ResourceTag/EnableKeyForAmazonDataZone\u0026#34;: \u0026#34;true\u0026#34;\r},\r\u0026#34;Null\u0026#34;: {\r\u0026#34;aws:ResourceTag/EnableKeyForAmazonDataZone\u0026#34;: \u0026#34;false\u0026#34;\r},\r\u0026#34;StringLike\u0026#34;: {\r\u0026#34;kms:ViaService\u0026#34;: \u0026#34;ssm.*.amazonaws.com\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;SecurityPolicyStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;aoss:GetSecurityPolicy\u0026#34;,\r\u0026#34;aoss:CreateSecurityPolicy\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;StringLike\u0026#34;: {\r\u0026#34;aoss:collection\u0026#34;: \u0026#34;bedrock-ide-*\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;GetFoundationModelStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;bedrock:GetFoundationModel\u0026#34;,\r\u0026#34;bedrock:GetFoundationModelAvailability\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:bedrock:*::foundation-model/*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;GetInferenceProfileStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;bedrock:GetInferenceProfile\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:bedrock:*:*:inference-profile/*\u0026#34;,\r\u0026#34;arn:aws:bedrock:*:*:application-inference-profile/*\u0026#34;\r]\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;ApplicationInferenceProfileStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;bedrock:CreateInferenceProfile\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:bedrock:*:*:application-inference-profile/*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;Null\u0026#34;: {\r\u0026#34;aws:RequestTag/AmazonDataZoneProject\u0026#34;: \u0026#34;true\u0026#34;,\r\u0026#34;aws:RequestTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;false\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;TagApplicationInferenceProfileStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;bedrock:TagResource\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:bedrock:*:*:application-inference-profile/*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;Null\u0026#34;: {\r\u0026#34;aws:ResourceTag/AmazonDataZoneProject\u0026#34;: \u0026#34;true\u0026#34;,\r\u0026#34;aws:RequestTag/AmazonDataZoneProject\u0026#34;: \u0026#34;true\u0026#34;,\r\u0026#34;aws:ResourceTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;false\u0026#34;,\r\u0026#34;aws:RequestTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;false\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;DeleteApplicationInferenceProfileStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;bedrock:DeleteInferenceProfile\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;arn:aws:bedrock:*:*:application-inference-profile/*\u0026#34;\r],\r\u0026#34;Condition\u0026#34;: {\r\u0026#34;Null\u0026#34;: {\r\u0026#34;aws:ResourceTag/AmazonDataZoneProject\u0026#34;: \u0026#34;true\u0026#34;,\r\u0026#34;aws:ResourceTag/AmazonDataZoneDomain\u0026#34;: \u0026#34;false\u0026#34;\r}\r}\r},\r{\r\u0026#34;Sid\u0026#34;: \u0026#34;ModelAccessUseCaseStatement\u0026#34;,\r\u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;,\r\u0026#34;Action\u0026#34;: [\r\u0026#34;bedrock:GetUseCaseForModelAccess\u0026#34;,\r\u0026#34;bedrock:PutUseCaseForModelAccess\u0026#34;\r],\r\u0026#34;Resource\u0026#34;: [\r\u0026#34;*\u0026#34;\r]\r}\r]\r} "
},
{
	"uri": "//localhost:1313/4-/4.4/",
	"title": "Tạo job Step Function và EventBridge",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/4-/",
	"title": "Tạo lambda lấy dữ liêu và trigger model",
	"tags": [],
	"description": "",
	"content": "Tạo lambda lấy dữ liêu và trigger model "
},
{
	"uri": "//localhost:1313/1-/1.4-api/",
	"title": "Xử lý dữ liệu",
	"tags": [],
	"description": "",
	"content": "Xử lý dữ liệu Tuy nhiên việc xử lý dữ liệu hiện đại không chỉ đơn thuần như vậy, ngoài ra còn rất nhiều bước như biến đổi, tách, chiết, convert\u0026hellip;\nBạn là một người làm data, tuy nhiên bạn chưa tưởng tượng được hết các bước để xử lý dữ liệu. Những hình dung việc xử lý dữ liệu ban đầu của mọi người thường là những thao tác cơ bản như loại bỏ giá trị trùng lặp hay xóa các ô null.\nTuy nhiên, trong thực tế hiện đại, xử lý dữ liệu là một quá trình toàn diện và có hệ thống. Nó không chỉ dừng lại ở việc \u0026ldquo;dọn dẹp\u0026rdquo; mà còn bao gồm nhiều công đoạn quan trọng sấy, băm chặt như sau:\nBiến đổi dữ liệu: chuẩn hóa định dạng, đổi kiểu dữ liệu, chuẩn hóa đơn vị đo lường.\nTách \u0026amp; gộp dữ liệu: trích xuất các trường con từ dữ liệu thô hoặc ghép nhiều nguồn dữ liệu lại với nhau.\nChuyển đổi \u0026amp; mã hóa: chuyển đổi dữ liệu giữa các hệ thống, mã hóa giá trị dạng phân loại thành số để phục vụ phân tích.\nLàm giàu dữ liệu: bổ sung thêm thông tin từ các nguồn ngoài để tăng giá trị phân tích.\nXử lý nâng cao: phát hiện ngoại lệ, chuẩn hóa dữ liệu theo chuẩn thống kê, tạo đặc trưng mới phục vụ machine learning.\nNói cách khác, xử lý dữ liệu chính là cầu nối quan trọng giữa dữ liệu thô và thông tin có thể hành động được, đảm bảo dữ liệu sạch, nhất quán và sẵn sàng cho phân tích, báo cáo hoặc huấn luyện mô hình.\n"
},
{
	"uri": "//localhost:1313/4-/4.0/",
	"title": "Các key cần chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Trước khi bắt đầu Trước khi bắt đầu bạn cần phải có các key cho lambda function hướng đến và hoạt động tốt\nDanh sách các app Để lấy package_name của các app,\nTruy cập: https://play.google.com Chọn các app bất kỳ cần checking:\nVí dụ chọn Tiktok\nCopy package_name =\u0026gt; Package_name: com.zhiliaoapp.musically\n"
},
{
	"uri": "//localhost:1313/5-/",
	"title": "Crawler và xử lý dữ liệu trên Glue",
	"tags": [],
	"description": "",
	"content": "Crawler và xử lý dữ liệu trên Glue Trên là một số dữ liệu mình đã thêm vào từ trước\n"
},
{
	"uri": "//localhost:1313/1-/1.5-distilbert-sst2/",
	"title": "Mô hình distilbert-sst2",
	"tags": [],
	"description": "",
	"content": "Mô hình distilbert-sst2 Giới thiệu distilBERT-SST2 là mô hình DistilBERT được tinh chỉnh trên tập dữ liệu SST-2 để phân tích cảm xúc nhị phân (tích cực/tiêu cực) ở cấp câu. Mô hình nhỏ gọn, suy luận nhanh, độ chính xác tốt cho các bài toán sentiment phổ biến.\nKhái niệm DistilBERT là phiên bản rút gọn của BERT qua kỹ thuật knowledge distillation: ít tham số hơn (~40%), suy luận nhanh hơn (đến ~60%) nhưng giữ phần lớn hiệu năng của BERT. SST-2 (Stanford Sentiment Treebank v2) gán nhãn cảm xúc nhị phân cho câu; đầu ra mô hình là xác suất/nhãn Positive hoặc Negative. Kết quả thường lấy theo Softmax trên hai lớp; có thể tùy ngưỡng cho các mục tiêu kinh doanh khác nhau. Phân loại văn bản thành tích cực tiêu cực Sở dĩ dùng model trên do dữ liệu lấy về có cột content chứa đánh giá của người dùng\nỨng dụng thực tế Phân tích cảm xúc đánh giá ứng dụng, phản hồi khách hàng, bài đăng mạng xã hội. Cảnh báo sớm và ưu tiên xử lý phản hồi tiêu cực trong quy trình hỗ trợ. Theo dõi xu hướng cảm xúc theo thời gian cho báo cáo thương hiệu/sản phẩm. Là bước tiền xử lý cho các pipeline nâng cao: phân loại chủ đề, định tuyến ticket, tóm tắt. "
},
{
	"uri": "//localhost:1313/1-/1.6-batchtransform/",
	"title": "Sagemaker Batch Transform",
	"tags": [],
	"description": "",
	"content": "Sagemaker Batch Transform Giới thiệu SageMaker Batch Transform là dịch vụ suy luận hàng loạt (offline) dùng để chạy mô hình ML trên tập dữ liệu có sẵn, lưu kết quả trực tiếp về S3. Phù hợp cho các kịch bản không yêu cầu độ trễ thấp và cần xử lý khối lượng dữ liệu lớn theo lô.\nKhái niệm Chạy inference theo lô thay vì theo yêu cầu thời gian thực. Đọc dữ liệu đầu vào từ S3 và ghi kết quả ra S3 dưới dạng file. Không cần triển khai Endpoint, chỉ chạy khi có job nên tối ưu chi phí cho xử lý định kỳ. Một inference cho một model:\nmodel_fn input_fn predict_fn output_fn Ứng dụng thực tế Gắn nhãn/suy luận cho kho dữ liệu lịch sử (ví dụ: đánh giá ứng dụng đã thu thập trên S3). Tạo đặc trưng nâng cao (feature enrichment) cho pipeline phân tích báo cáo. Phân loại, phát hiện chủ đề/cảm xúc, lọc nội dung quy mô lớn. Chạy lại suy luận theo đợt khi có phiên bản mô hình mới. Các lưu ý Use batch transform when you need to do the following:\nPreprocess datasets to remove noise or bias that interferes with training or inference from your dataset. Get inferences from large datasets. Run inference when you don\u0026rsquo;t need a persistent endpoint. Associate input records with inferences to help with the interpretation of results. . Note that Batch Transform doesn\u0026rsquo;t support CSV-formatted input that contains embedded newline characters. You can control the size of the mini-batches by using the BatchStrategy and MaxPayloadInMB parameters. MaxPayloadInMB must not be greater than 100 MB. If you specify the optional MaxConcurrentTransforms parameter, then the value of (MaxConcurrentTransforms * MaxPayloadInMB) must also not exceed 100 MB.\n"
},
{
	"uri": "//localhost:1313/6/",
	"title": "Tạo báo cáo trên QuickSight và truy vấn Athena",
	"tags": [],
	"description": "",
	"content": "Tạo báo cáo trên QuickSight và truy vấn Athena Tạo báo cáo trên QuickSight và truy vấn Athena\nNội dung:\nThêm code vào lambda function Chat với chatbot Check log Export to S3 "
},
{
	"uri": "//localhost:1313/7-/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Trong bài lab này chúng ta đã sử dụng các dịch vụ S3, Lambda Function, DynamoDB, API Gateway. Các dịch vụ này đều có chi phí khá là rẻ và free cho tài khoản 12 tháng nên ko cần phải xóa tài nguyên.\nNếu vẫn muốn xóa thì đây là lần lượt các bước:\nXóa S3 Bucket Vào S3 chọn bucket và chọn workshoph và chọn Empty. sau đó chọn Delete làm theo các hiển thị tiếp theo để xóa.\nXóa Lambda function Vào Lambda function chọn function chọn BotTele và chọn Actions chọn Delete để xóa.\nXóa model trên Sagemaker AI Truy cập vào giao diện Sagemaker AI, chọn model và xóa model đã tạo để tránh phát sinh chi phí\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]